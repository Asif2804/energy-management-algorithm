{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asif2804/energy-management-algorithm/blob/main/XAI_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9dZf4lyXDop"
      },
      "source": [
        "Literature to compare XAI models: [link text](https://arxiv.org/html/2503.04261v1?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-JlJ77QibRv"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWf04sDHitGO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "9fb803c0-23b6-4f5f-eab8-75b023a04eca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'lime'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-409664261.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlime_tabular\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLimeTabularExplainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpermutation_importance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPartialDependenceDisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lime'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tracemalloc\n",
        "import random\n",
        "\n",
        "from collections import defaultdict\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, r2_score\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#!pip install lime\n",
        "#!pip install dice-ml\n",
        "\n",
        "\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "import shap\n",
        "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
        "import dice_ml\n",
        "from dice_ml import Dice\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQuZqYYfi9-5"
      },
      "outputs": [],
      "source": [
        "#Loading Data\n",
        "df = pd.read_csv('/content/heart.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pQ740nmZNSj"
      },
      "source": [
        "**Attribute information:**\n",
        "1. age\n",
        "2. sex\n",
        "3. chest pain type\n",
        "4. resting blood pressure\n",
        "5. serum cholestoral in mg/dl\n",
        "6. fasting blood sugar > 120 mg/dl\n",
        "7. resting electrocardiographic results\n",
        "8. maximum heart rate achieved\n",
        "9. exercise induced angina - (Wether the patient has chestpain durng Exercise)\n",
        "10. oldpeak = ST depression induced by exercise relative to rest\n",
        "11. the slope of the peak exercise ST segment ()\n",
        "12. number of major vessels (0-3) colored by flourosopy\n",
        "13. thal: 0 = normal; 1 = fixed defect; 2 = reversable defect - (A type of blood disorder tested during heart evaluation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge_H1BBUjIYF"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lp4H1PKEZOkW"
      },
      "outputs": [],
      "source": [
        "#Check correlations with target\n",
        "correlations = df.corr(numeric_only=True)['target'].sort_values(ascending=False)\n",
        "print(\"\\nCorrelations with target:\\n\", correlations)\n",
        "\n",
        "#Check target class distribution\n",
        "print(\"\\nTarget class distribution:\\n\", df['target'].value_counts(normalize=True))\n",
        "\n",
        "#Plot class distribution\n",
        "df['target'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
        "plt.title(\"Class Distribution Before Duplicate Removal\")\n",
        "plt.xlabel(\"Target (0 = No Disease, 1 = Heart Disease)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "print(f\"\\nData shape after dropping duplicates: {df.shape}\")\n",
        "\n",
        "#Class distribution after duplicate removal\n",
        "df['target'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
        "plt.title(\"Class Distribution After Duplicate Removal\")\n",
        "plt.xlabel(\"Target (0 = No Disease, 1 = Heart Disease)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "I0-JdmwoysF7",
        "outputId": "5f3dba95-12eb-4bce-9987-e26a63196a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1354606324.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Drop duplicate rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nData shape after dropping duplicates: {df.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Class distribution after duplicate removal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rl2FjQVJ1Mza"
      },
      "outputs": [],
      "source": [
        "#Separate features (X) and target label (y)\n",
        "X = df.drop(\"target\", axis=1)\n",
        "y = df[\"target\"]\n",
        "\n",
        "#Treat all features as numeric for simplicity\n",
        "numerical_cols = X.columns.tolist()  #all columns are numeric\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "#Single transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_cols)\n",
        "    ])\n",
        "\n",
        "\n",
        "for run in range(5):  #number of runs\n",
        "    random_seed = np.random.randint(0, 61)\n",
        "\n",
        "#Train test split\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state= random_seed )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9GdHO7a2puP"
      },
      "source": [
        "# Training models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwldsXy3TjoU"
      },
      "source": [
        "F1 - bELOW 0.75 is not admissable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTTHM-bo2pD2"
      },
      "outputs": [],
      "source": [
        "#Print test set shape\n",
        "print(X_test_raw.shape)  #How many rows in the test set?\n",
        "\n",
        "#4 ML models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=100, max_depth=5, random_state=42  #No of trees, depth of each tree,\n",
        "    ),\n",
        "    \"KNN\": KNeighborsClassifier(\n",
        "        n_neighbors=5, weights='uniform', metric='minkowski' #No. of neighbors used, equal weight across neighbors, default distance\n",
        "    ),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        n_estimators=200, max_depth=5, learning_rate=0.05, eval_metric='logloss', random_state=42 #shrinking stepsize, evaluation metric\n",
        "    ),\n",
        "    \"MLP\": MLPClassifier(\n",
        "        hidden_layer_sizes=(32, 16), max_iter=500, alpha=0.001, random_state=42 #2 hidden layers, max num of training, regularization\n",
        "    )\n",
        "}\n",
        "\n",
        "pipelines = {\n",
        "    name: Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "    for name, model in models.items()\n",
        "}\n",
        "\n",
        "results = {} #Store trained pipelines and metrics\n",
        "\n",
        "for name, pipeline in pipelines.items():\n",
        "    pipeline.fit(X_train_raw, y_train) #Fit pipeline on data\n",
        "    y_pred = pipeline.predict(X_test_raw) #Predict labels on test data\n",
        "\n",
        "    results[name] = {                       #Store trained pipeline and metrics\n",
        "        \"pipeline\": pipeline,\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"auc\": roc_auc_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred),\n",
        "        \"recall\": recall_score(y_test, y_pred),\n",
        "        \"f1\": f1_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "# Print metrics\n",
        "for name, metrics in results.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "    print(f\"AUC: {metrics['auc']:.4f}\")\n",
        "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert results to a DataFrame\n",
        "metrics_df = pd.DataFrame(results).T  #transpose so models are rows\n",
        "\n",
        "#Plot grouped bar chart\n",
        "metrics_df.plot(kind=\"bar\", figsize=(10, 6))\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0, 1)  #since metrics are between 0 and 1\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title=\"Metric\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "4CziWf_x20fF",
        "outputId": "bbdee08f-bee5-4ee9-d50c-4b45e4aa6734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1753812984.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Convert results to a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[0;31m#transpose so models are rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Plot grouped bar chart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmetrics_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdEWC6v0AH5b"
      },
      "source": [
        "# Lime for Random Forest (local explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EXM1fZDASoW"
      },
      "outputs": [],
      "source": [
        "print(X_test_raw.shape)  #How many rows in the test set?\n",
        "\n",
        "#Extract preprocessor and trained model\n",
        "rf_pipeline = results[\"Random Forest\"][\"pipeline\"]         #Take trained pipeline from above\n",
        "preprocessor = rf_pipeline.named_steps[\"preprocessor\"]     #Accesses to pull out just the data transformation part\n",
        "rf_model = rf_pipeline.named_steps[\"classifier\"]           #Accessing to pull out just the ML model\n",
        "\n",
        "#Preprocess full training data for LIME background\n",
        "X_train_processed = preprocessor.transform(X_train_raw)\n",
        "\n",
        "#Create LIME explainer\n",
        "explainer = LimeTabularExplainer(\n",
        "    training_data=X_train_processed, #The processed training data\n",
        "    feature_names=preprocessor.get_feature_names_out(), #post pre-processing\n",
        "    class_names=['No Disease', 'Heart Disease'], #Target lable\n",
        "    mode='classification',\n",
        "    discretize_continuous=True\n",
        ")\n",
        "\n",
        "#One test sample patient\n",
        "sample_index = 44\n",
        "X_one_raw = X_test_raw.iloc[[sample_index]] #Data before pre-processing\n",
        "X_one_transformed = preprocessor.transform(X_one_raw) #Preprocessed Data\n",
        "\n",
        "#Wrap predict_proba() so LIME can call it\n",
        "def rf_predict_proba(x):\n",
        "    return rf_model.predict_proba(x)\n",
        "\n",
        "#LIME explanation\n",
        "lime_exp = explainer.explain_instance(\n",
        "    data_row=X_one_transformed[0], # processed features for your one patient\n",
        "    predict_fn=rf_predict_proba, #The function LIME will call to get model predictions\n",
        "    num_features=7\n",
        "\n",
        ")\n",
        "\n",
        "r2 = lime_exp.score\n",
        "print(f\"LIME surrogate R² fidelity: {r2:.4f}\")\n",
        "\n",
        "#Visualizing\n",
        "lime_exp.show_in_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTmcI8IDaj8Y"
      },
      "source": [
        "LIME graph is explaining the model predicted a 61% probability of Heart Disease for patient 43.\n",
        "\n",
        "The most influcential features are:\n",
        "*   Thalassemia\n",
        "*   Slope of the peak exercise ST segmen\n",
        "*   Exercise-Induced Angina\n",
        "\n",
        "Since the fidelity is low (0.26), the linear approximation doesnt capture the full complexity of the model here.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_vJXoN7BT3j"
      },
      "source": [
        "# Lime for K-nearest Neighbor (local explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAA5AnUaBTeJ"
      },
      "outputs": [],
      "source": [
        "print(X_test_raw.shape)  #How many rows in the test set?\n",
        "\n",
        "#Extract trained KNN pipeline\n",
        "knn_pipeline = results[\"KNN\"][\"pipeline\"]  #Taking the pipeline for KNN\n",
        "preprocessor = knn_pipeline.named_steps[\"preprocessor\"]\n",
        "knn_model = knn_pipeline.named_steps[\"classifier\"]\n",
        "\n",
        "# Preprocess training data for background\n",
        "X_train_processed = preprocessor.transform(X_train_raw)\n",
        "\n",
        "# Create LIME explainer\n",
        "lime_explainer = LimeTabularExplainer(\n",
        "    training_data=X_train_processed,          # Processed training data\n",
        "    feature_names=preprocessor.get_feature_names_out(), #Names after processing\n",
        "    class_names=['No Disease', 'Heart Disease'], #Target value\n",
        "    mode='classification',                       #classification problem\n",
        "    discretize_continuous=True\n",
        ")\n",
        "\n",
        "#test sample\n",
        "sample_index = 36\n",
        "X_sample_raw = X_test_raw.iloc[[sample_index]] #raw data before the pre-processing\n",
        "X_sample_transformed = preprocessor.transform(X_sample_raw) # preprocessed data\n",
        "\n",
        "def knn_predict(X):\n",
        "    return knn_model.predict_proba(X)\n",
        "\n",
        "#LIME explanation\n",
        "lime_exp = lime_explainer.explain_instance(\n",
        "    data_row=X_sample_transformed[0], #processed features for this patient\n",
        "    predict_fn=knn_predict, #function LIME calls to get predictions\n",
        "    num_features=7 # top 7 fearues\n",
        ")\n",
        "r2 = lime_exp.score\n",
        "print(f\"LIME surrogate R² fidelity: {r2:.4f}\")\n",
        "\n",
        "#Show LIME explanation\n",
        "lime_exp.show_in_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPLpNILie0uY"
      },
      "source": [
        "LIME graph is explaining the model predicted a 80% probability of Heart Disease for patient 43.\n",
        "\n",
        "The most influcential features are:\n",
        "*   Thalassemia\n",
        "*   Exercise-Induced Angina\n",
        "*   Slope of the peak exercise ST segmen\n",
        "\n",
        "Since the fidelity is again low (0.41), the linear approximation does not approximate the Random Forests local behavior very well for this patient.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_3sGi9wfiQA"
      },
      "source": [
        "# Lime for XGBoost (local explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9PiXSObhAwE"
      },
      "outputs": [],
      "source": [
        "#XGBoost pipeline\n",
        "xgb_pipeline = results[\"XGBoost\"][\"pipeline\"]\n",
        "\n",
        "#Prepare the training data\n",
        "preprocessor = xgb_pipeline.named_steps[\"preprocessor\"]\n",
        "X_train_processed = preprocessor.transform(X_train_raw)\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "#Set up the LIME explainer\n",
        "explainer = LimeTabularExplainer(\n",
        "    training_data=X_train_processed,\n",
        "    feature_names=feature_names,\n",
        "    class_names=[\"No Disease\", \"Heart Disease\"],  #Match class names\n",
        "    mode=\"classification\",\n",
        "    discretize_continuous=True\n",
        ")\n",
        "\n",
        "#Test instance to explain\n",
        "instance_idx = 22\n",
        "instance = X_test_raw.iloc[[instance_idx]]  #DataFrame slice for correct columns\n",
        "\n",
        "#Preprocess the instance\n",
        "instance_processed = preprocessor.transform(instance)\n",
        "\n",
        "#Ensures input is always in the right format\n",
        "def xgb_predict_proba_wrapper(X):\n",
        "    if not isinstance(X, pd.DataFrame):\n",
        "        X = pd.DataFrame(X, columns=X_train_raw.columns)\n",
        "    return xgb_pipeline.predict_proba(X)\n",
        "\n",
        "#Generate the LIME explanation\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=instance_processed[0],\n",
        "    predict_fn=xgb_predict_proba_wrapper,\n",
        "    num_features=7\n",
        ")\n",
        "\n",
        "#visiualize\n",
        "exp.show_in_notebook(show_table=True, show_all=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5SPQPCIhflI"
      },
      "source": [
        "# Lime for MPL Classifire (local explaination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL_oB695hfJe"
      },
      "outputs": [],
      "source": [
        "mlp_pipeline = results[\"MLP\"][\"pipeline\"]\n",
        "\n",
        "#Preparetraining data\n",
        "preprocessor = mlp_pipeline.named_steps[\"preprocessor\"]\n",
        "X_train_processed = preprocessor.transform(X_train_raw)\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "#Initialize LIME explainer\n",
        "explainer_mlp = LimeTabularExplainer(\n",
        "    training_data=X_train_processed,\n",
        "    feature_names=feature_names,\n",
        "    class_names=[\"No Disease\", \"Disease\"],\n",
        "    mode=\"classification\",\n",
        "    discretize_continuous=True\n",
        ")\n",
        "\n",
        "#Choose a test instance\n",
        "instance_idx = 36\n",
        "instance = X_test_raw.iloc[[instance_idx]] #Pass a DataFrame slice\n",
        "\n",
        "#Preprocess the instance for the MLP pipeline\n",
        "instance_processed = preprocessor.transform(instance)\n",
        "\n",
        "\n",
        "#predict_fn that handles both DataFrame and NumPy array inputs\n",
        "def mlp_predict_proba_wrapper(X):\n",
        "    #Ensure input is a DataFrame with correct column names\n",
        "    if not isinstance(X, pd.DataFrame):\n",
        "        X = pd.DataFrame(X, columns=X_train_raw.columns) #Use original column names\n",
        "    return mlp_pipeline.predict_proba(X)\n",
        "\n",
        "\n",
        "#Generate the explanation\n",
        "exp_mlp = explainer_mlp.explain_instance(\n",
        "    data_row=instance_processed[0], #Use the processed instance data row\n",
        "    predict_fn=mlp_predict_proba_wrapper, #Use the wrapper function\n",
        "    num_features= 7 # top 7 features\n",
        ")\n",
        "\n",
        "#Visualize\n",
        "exp_mlp.show_in_notebook(show_table=True, show_all=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tHSKYoGGLKz"
      },
      "source": [
        "# SHAP for Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "w3JRwPTiGWXP",
        "outputId": "aee2ee72-5d71-4821-be77-927f7bc43528"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-838794848.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Get RF pipeline from results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrf_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Random Forest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pipeline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#Get preprocessor and classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ],
      "source": [
        "##################### Global #######################\n",
        "\n",
        "#Get RF pipeline from results\n",
        "rf_pipeline = results['Random Forest']['pipeline']\n",
        "#Get preprocessor and classifier\n",
        "preprocessor = rf_pipeline.named_steps['preprocessor']\n",
        "rf_model = rf_pipeline.named_steps['classifier']\n",
        "\n",
        "X_test_transformed = preprocessor.transform(X_test_raw) #Use raw test set to get full transformed data\n",
        "feature_names = preprocessor.get_feature_names_out() #feature names\n",
        "\n",
        "#TreeExplainer for the RF\n",
        "explainer = shap.TreeExplainer(rf_model)\n",
        "shap_values = explainer.shap_values(X_test_transformed) #Pass full test set\n",
        "\n",
        "#For class 1 (Heart Disease)\n",
        "shap_values_class1 = shap_values[:, :, 1]  #Switch between class 1/2\n",
        "\n",
        "#\n",
        "# This should now work\n",
        "shap.summary_plot(\n",
        "    shap_values_class1,\n",
        "    X_test_transformed,\n",
        "    feature_names=feature_names\n",
        ")\n",
        "\n",
        "\n",
        "#Get models original probability predictions for class 1\n",
        "y_pred_full = rf_model.predict_proba(X_test_transformed)[:, 1]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7E4mQ9Ti_9t"
      },
      "source": [
        "SHAP global summary plot is explaining which features most influence the Random Forest models predictions for Heart Disease across all patients.\n",
        "\n",
        "The most influential features are:\n",
        "* Chest Pain Type (num__cp)\n",
        "* Number of Major Vessels (num__ca)\n",
        "* Thalassemia (num__thal)\n",
        "* Exercise-Induced Angina (num__exang)\n",
        "* Maximum Heart Rate Achieved (num__thalach)\n",
        "\n",
        "Since the fidelity is very high (0.99), the top features identified by SHAP capture nearly all of the Random Forests behavior, meaning this explanation closely matches the models predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S65z2dO0pFq"
      },
      "outputs": [],
      "source": [
        "####################### Local SHAP Explanation ############################\n",
        "print(X_test_raw.shape)  #How many rows in the test set?\n",
        "\n",
        "sample_index = 43  #patient\n",
        "#Slice one row\n",
        "X_sample = X_test_transformed[sample_index:sample_index+1]\n",
        "\n",
        "#Get SHAP values for this sample\n",
        "shap_values_sample = explainer.shap_values(X_sample)\n",
        "\n",
        "#The SHAP values for class 1 (Heart Disease)\n",
        "shap_values_sample_class1 = shap_values_sample[:, :, 1]\n",
        "\n",
        "#Convert to 1D array for waterfall plot\n",
        "shap_values_flat = shap_values_sample_class1.flatten()\n",
        "\n",
        "#Get expected value for class 1\n",
        "expected_value = explainer.expected_value[1]\n",
        "\n",
        "#input features\n",
        "X_dense = X_sample.toarray()[0] if hasattr(X_sample, \"toarray\") else X_sample[0]\n",
        "\n",
        "# Plot waterfall\n",
        "shap.plots._waterfall.waterfall_legacy(\n",
        "    expected_value=expected_value,\n",
        "    shap_values=shap_values_flat,\n",
        "    feature_names=feature_names,\n",
        "    features=X_dense,\n",
        "    max_display=13  # Show all features\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0B4sMeCNYy7"
      },
      "source": [
        "SHAP local explanation is explaining the model predicted a 61% probability of Heart Disease for patient 43.\n",
        "\n",
        "The most influential features are:\n",
        "\n",
        "* Chest Pain Type (num__cp)\n",
        "* Exercise-Induced Angina (num__exang)\n",
        "* Number of Major Vessels (num__ca)\n",
        "* Thalassemia (num__thal)\n",
        "* Maximum Heart Rate Achieved (num__thalach)\n",
        "\n",
        "Since SHAP calculates contributions directly from the model without relying on a linear surrogate, the explanation Should be accurate for the Random Forests prediction for this patient.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Ol9jJjgQcI"
      },
      "source": [
        "# SHAP for K-Nearest Neighbor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhJoRexf1sID"
      },
      "outputs": [],
      "source": [
        "##################### Global #######################\n",
        "USE_SUBSET =  False     #False/True\n",
        "SUBSET_SIZE = 2      #Samples\n",
        "\n",
        "#100 random training samples\n",
        "X_background = preprocessor.transform(X_train_raw.sample(100, random_state=42))\n",
        "X_background = X_background.toarray() if hasattr(X_background, \"toarray\") else X_background\n",
        "\n",
        "#Transform test set with the same preprocessor\n",
        "X_test_transformed = preprocessor.transform(X_test_raw)\n",
        "X_test_dense = X_test_transformed.toarray() if hasattr(X_test_transformed, \"toarray\") else X_test_transformed\n",
        "\n",
        "#Use subset or full test set\n",
        "X_test_subset = X_test_dense[:SUBSET_SIZE] if USE_SUBSET else X_test_dense\n",
        "\n",
        "#Wrapper so SHAP only explains probability for class 1 (Heart disease)\n",
        "def predict_class1(X):\n",
        "    return knn_model.predict_proba(X)[:, 1]\n",
        "\n",
        "#KernalSHAP created\n",
        "explainer = shap.KernelExplainer(predict_class1, X_background)\n",
        "\n",
        "#Compute SHAP values for the subset\n",
        "shap_vals_raw = explainer.shap_values(X_test_subset)\n",
        "\n",
        "shap_vals_class1 = np.array(shap_vals_raw)\n",
        "\n",
        "#Fix the shape issues\n",
        "if shap_vals_class1.shape[::-1] == X_test_subset.shape:\n",
        "    shap_vals_class1 = shap_vals_class1.T\n",
        "elif shap_vals_class1.shape != X_test_subset.shape:\n",
        "    raise ValueError(f\"Unexpected SHAP shape {shap_vals_class1.shape}, expected {X_test_subset.shape}\")\n",
        "\n",
        "\n",
        "#SHAP Summary Plot\n",
        "expl_all = shap.Explanation(\n",
        "    values=shap_vals_class1,\n",
        "    base_values=explainer.expected_value,\n",
        "    data=X_test_subset,\n",
        "    feature_names=preprocessor.get_feature_names_out()\n",
        ")\n",
        "shap.plots.beeswarm(expl_all, max_display=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAOterE9muHn"
      },
      "source": [
        "SHAP global explanation is explaining which features most influence the KNN models predictions for Heart Disease across all patients.\n",
        "\n",
        "The most influential features are:\n",
        "\n",
        "* Thalassemia (num__thal)\n",
        "* Sex (num__sex)\n",
        "* Exercise-Induced Angina (num__exang)\n",
        "* Chest Pain Type (num__cp)\n",
        "* Maximum Heart Rate Achieved (num__thalach)\n",
        "\n",
        "The top features account for most of the variation in the models predictions, as shown by a SHAP fidelity score of R² = 0.8851 when only the top 10 features are used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlRaDfS8cPuZ"
      },
      "outputs": [],
      "source": [
        "####################### Local SHAP Explanation ############################\n",
        "print(X_test_raw.shape)  #How many rows in the test set?\n",
        "\n",
        "sample_index = 43\n",
        "X_one_raw = X_test_raw.iloc[[sample_index]]\n",
        "X_one_transformed = preprocessor.transform(X_one_raw)\n",
        "\n",
        "#KernelExplainer needs a background dataset\n",
        "background = shap.sample(X_train_processed, 50, random_state=42)\n",
        "\n",
        "#Use predict_proba for SHAP\n",
        "def knn_predict(x):\n",
        "    return knn_model.predict_proba(x)  #make sure knn_model is your fitted KNN classifier\n",
        "\n",
        "#KernelExplainer\n",
        "explainer_knn = shap.KernelExplainer(knn_predict, background)\n",
        "\n",
        "#Compute SHAP values for this sample (for both classes)\n",
        "shap_values = explainer_knn.shap_values(X_one_transformed)\n",
        "\n",
        "#for class 1 (Heart Disease)\n",
        "shap_values_class1 = shap_values[0, :, 1]  #SHAP values for patient 100, class 1\n",
        "\n",
        "#Create SHAP Explanation object for waterfall plot\n",
        "expl_knn = shap.Explanation(\n",
        "    values=shap_values_class1,\n",
        "    base_values=explainer_knn.expected_value[1],\n",
        "    data=X_one_transformed.toarray()[0] if hasattr(X_one_transformed, \"toarray\") else X_one_transformed[0],\n",
        "    feature_names=preprocessor.get_feature_names_out(),\n",
        ")\n",
        "\n",
        "#Plot waterfall\n",
        "shap.plots.waterfall(expl_knn, max_display=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZvNr8B3nmF9"
      },
      "source": [
        "SHAP local explanation is explaining the model predicted an 80% probability of Heart Disease for patient 43.\n",
        "\n",
        "The most influential features are:\n",
        "\n",
        "* Chest Pain Type (num__cp)\n",
        "* Thalassemia (num__thal)\n",
        "* Sex (num__sex)\n",
        "* Maximum Heart Rate Achieved (num__thalach)\n",
        "* Serum Cholesterol (num__chol)\n",
        "\n",
        "Since SHAP calculates contributions directly from the KNN model without relying on a surrogate, the explanation accurately reflects the models prediction for this patient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MddlIC96su0u"
      },
      "source": [
        "# SHAP for XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYXLsum1s9lD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "c794b893-43a1-4702-b277-333e453b38d9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2974313677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Get trained XGBoost pipeline and the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"XGBoost\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pipeline\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"preprocessor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#the actual XGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ],
      "source": [
        "#Get trained XGBoost pipeline and the classifier\n",
        "xgb_pipeline = results[\"XGBoost\"][\"pipeline\"]\n",
        "preprocessor = xgb_pipeline.named_steps[\"preprocessor\"]\n",
        "xgb_model = xgb_pipeline.named_steps[\"classifier\"]  #the actual XGBClassifier\n",
        "\n",
        "#Preprocess training and test sets\n",
        "X_background = preprocessor.transform(X_train_raw.sample(100, random_state=42))\n",
        "X_background = X_background.toarray() if hasattr(X_background, \"toarray\") else X_background\n",
        "\n",
        "X_test_transformed = preprocessor.transform(X_test_raw)\n",
        "X_test_dense = X_test_transformed.toarray() if hasattr(X_test_transformed, \"toarray\") else X_test_transformed\n",
        "\n",
        "#Optionally use a subset of test data for speed\n",
        "USE_SUBSET = False\n",
        "SUBSET_SIZE = 2\n",
        "X_test_subset = X_test_dense[:SUBSET_SIZE] if USE_SUBSET else X_test_dense\n",
        "\n",
        "#Create SHAP TreeExplainer\n",
        "explainer = shap.TreeExplainer(xgb_model)\n",
        "\n",
        "#Compute SHAP values for both classes\n",
        "shap_values = explainer.shap_values(X_test_subset)\n",
        "shap_vals_class1 = shap_values[1] if isinstance(shap_values, list) else shap_values  #binary models\n",
        "\n",
        "#beeswarm plot\n",
        "expl_all = shap.Explanation(\n",
        "    values=shap_vals_class1,\n",
        "    base_values=explainer.expected_value[1] if isinstance(explainer.expected_value, (list, np.ndarray)) else explainer.expected_value,\n",
        "    data=X_test_subset,\n",
        "    feature_names=preprocessor.get_feature_names_out()\n",
        ")\n",
        "\n",
        "shap.plots.beeswarm(expl_all, max_display=50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3tcQFMYt8Lm"
      },
      "outputs": [],
      "source": [
        "##################### Local #######################\n",
        "xgb_pipeline = results[\"XGBoost\"][\"pipeline\"]\n",
        "preprocessor = xgb_pipeline.named_steps[\"preprocessor\"]\n",
        "xgb_model = xgb_pipeline.named_steps[\"classifier\"]\n",
        "\n",
        "X_test_transformed = preprocessor.transform(X_test_raw)\n",
        "X_test_dense = X_test_transformed.toarray() if hasattr(X_test_transformed, \"toarray\") else X_test_transformed\n",
        "\n",
        "#Create a SHAP TreeExplainer for xgb\n",
        "explainer = shap.TreeExplainer(xgb_model)\n",
        "\n",
        "#patient\n",
        "patient_idx = 43  #Change this index for other patients\n",
        "x_patient = X_test_dense[patient_idx:patient_idx+1]  #Keep as 2D\n",
        "\n",
        "#Compute SHAP values for this patient\n",
        "shap_values = explainer.shap_values(x_patient)\n",
        "shap_vals_class1 = shap_values[1] if isinstance(shap_values, list) else shap_values\n",
        "\n",
        "#Build a SHAP Explanation object for plotting\n",
        "expl_patient = shap.Explanation(\n",
        "    values=shap_vals_class1[0],\n",
        "    base_values=explainer.expected_value[1] if isinstance(explainer.expected_value, (list, np.ndarray)) else explainer.expected_value,\n",
        "    data=x_patient[0],\n",
        "    feature_names=preprocessor.get_feature_names_out()\n",
        ")\n",
        "\n",
        "#Visualize as a waterfall plot (local explanation)\n",
        "shap.plots.waterfall(expl_patient, max_display=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD4l9achuPQ0"
      },
      "source": [
        "# SHAP for MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V46RRuI4vh40"
      },
      "outputs": [],
      "source": [
        "##################### Global #######################\n",
        "\n",
        "USE_SUBSET = False\n",
        "SUBSET_SIZE = 2\n",
        "\n",
        "#MLP pipeline and classifier\n",
        "mlp_pipeline = results[\"MLP\"][\"pipeline\"]\n",
        "preprocessor = mlp_pipeline.named_steps[\"preprocessor\"]\n",
        "mlp_model = mlp_pipeline.named_steps[\"classifier\"]\n",
        "\n",
        "X_background = preprocessor.transform(X_train_raw.sample(100, random_state=42))\n",
        "X_background = X_background.toarray() if hasattr(X_background, \"toarray\") else X_background\n",
        "\n",
        "X_test_transformed = preprocessor.transform(X_test_raw)\n",
        "X_test_dense = X_test_transformed.toarray() if hasattr(X_test_transformed, \"toarray\") else X_test_transformed\n",
        "\n",
        "#Use subset or full test set\n",
        "X_test_subset = X_test_dense[:SUBSET_SIZE] if USE_SUBSET else X_test_dense\n",
        "\n",
        "#Wrap\n",
        "def predict_class1(X):\n",
        "    return mlp_model.predict_proba(X)[:, 1]\n",
        "\n",
        "#Create a KernelExplainer\n",
        "explainer = shap.KernelExplainer(predict_class1, X_background)\n",
        "\n",
        "#Compute SHAP values for the subset\n",
        "shap_vals_raw = explainer.shap_values(X_test_subset)\n",
        "\n",
        "shap_vals_class1 = np.array(shap_vals_raw)\n",
        "\n",
        "#Fix shape mismatch\n",
        "if shap_vals_class1.shape[::-1] == X_test_subset.shape:\n",
        "    shap_vals_class1 = shap_vals_class1.T\n",
        "elif shap_vals_class1.shape != X_test_subset.shape:\n",
        "    raise ValueError(f\"Unexpected SHAP shape {shap_vals_class1.shape}, expected {X_test_subset.shape}\")\n",
        "\n",
        "\n",
        "#Create a SHAP Explanation\n",
        "expl_all = shap.Explanation(\n",
        "    values=shap_vals_class1,\n",
        "    base_values=explainer.expected_value,\n",
        "    data=X_test_subset,\n",
        "    feature_names=preprocessor.get_feature_names_out()\n",
        ")\n",
        "\n",
        "#beeswarm plot\n",
        "shap.plots.beeswarm(expl_all, max_display=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0X-lO3uuTIQ"
      },
      "outputs": [],
      "source": [
        "######################## LOCAL #######################\n",
        "#MLP pipeline and components\n",
        "mlp_pipeline = results[\"MLP\"][\"pipeline\"]\n",
        "preprocessor = mlp_pipeline.named_steps[\"preprocessor\"]\n",
        "mlp_model = mlp_pipeline.named_steps[\"classifier\"]\n",
        "\n",
        "X_background = preprocessor.transform(X_train_raw.sample(100, random_state=42))\n",
        "X_background = X_background.toarray() if hasattr(X_background, \"toarray\") else X_background\n",
        "\n",
        "X_test_transformed = preprocessor.transform(X_test_raw)\n",
        "X_test_dense = X_test_transformed.toarray() if hasattr(X_test_transformed, \"toarray\") else X_test_transformed\n",
        "\n",
        "#Select one patient to explain\n",
        "patient_idx = 0\n",
        "x_patient = X_test_dense[patient_idx:patient_idx+1]\n",
        "\n",
        "#probability for Heart Disease (class 1)\n",
        "def mlp_predict_class1(X):\n",
        "    return mlp_model.predict_proba(X)[:, 1]\n",
        "\n",
        "#Create KernelExplainer\n",
        "explainer = shap.KernelExplainer(mlp_predict_class1, X_background)\n",
        "\n",
        "#Compute SHAP values for this patient\n",
        "shap_vals = explainer.shap_values(x_patient)\n",
        "shap_vals_class1 = np.array(shap_vals)  #convert to array if list\n",
        "\n",
        "#Ensure the shape matches the input\n",
        "if shap_vals_class1.ndim > 1 and shap_vals_class1.shape[0] != x_patient.shape[0]:\n",
        "    shap_vals_class1 = shap_vals_class1.T\n",
        "\n",
        "#Explainer\n",
        "expl_patient = shap.Explanation(\n",
        "    values=shap_vals_class1[0],\n",
        "    base_values=explainer.expected_value,\n",
        "    data=x_patient[0],\n",
        "    feature_names=preprocessor.get_feature_names_out()\n",
        ")\n",
        "\n",
        "\n",
        "#local waterfall plot\n",
        "shap.plots.waterfall(expl_patient, max_display=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe_pmhq1QnRq"
      },
      "source": [
        "# PFI Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwZYP1A2Qq74"
      },
      "outputs": [],
      "source": [
        "########################## PFI Model ################################\n",
        "def run_pfi(model,          #Trained model\n",
        "            X_test, y_test, #Preprocessed test data\n",
        "            feature_names,  #List or array of feature names\n",
        "            model_name=\"Model\", #Name for labeling the plot\n",
        "            metric='roc_auc', #Performance metric used\n",
        "            repeats=10 #No of shuffles per feature.\n",
        "            ):\n",
        "\n",
        "\n",
        "    result = permutation_importance(model, X_test, y_test,\n",
        "                                     n_repeats=repeats,  #Randomly shuffles that feature repeats times for each feature\n",
        "                                     random_state=42,\n",
        "                                     scoring=metric) #Measures how much the models performance drops, larger performance drops = feature is more important\n",
        "\n",
        "    #Sorts the features by average importance\n",
        "    sorted_idx = np.argsort(result.importances_mean)[::-1]\n",
        "\n",
        "    #Print table of top features\n",
        "    for i in sorted_idx:\n",
        "     print(f\"{feature_names[i]}: {result.importances_mean[i]:.4f} ± {result.importances_std[i]:.4f}\")\n",
        "\n",
        "    #Bar chart of importance\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.barh(np.array(feature_names)[sorted_idx], result.importances_mean[sorted_idx])\n",
        "    plt.xlabel(f\"Permutation Importance ({metric})\")\n",
        "    plt.title(f\"Global Feature Importance - {model_name}\")\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.show()\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ngMBdQyLcIh"
      },
      "source": [
        "# PFI for Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXJwfZM8LbdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "f1056750-e0e1-4631-c5f5-3dc35a463330"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'preprocessor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3540125827.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Permutation Feature Importance for RandomForest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf_pfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_pfi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RandomForest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocessor' is not defined"
          ]
        }
      ],
      "source": [
        "feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "print(\"Permutation Feature Importance for RandomForest\")\n",
        "rf_pfi = run_pfi(rf_model, X_test_transformed, y_test, feature_names, model_name=\"RandomForest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m8Q9AOaH8-G"
      },
      "source": [
        "# PFI for K-nearest Neighboor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2TnZdC2MQW4"
      },
      "outputs": [],
      "source": [
        "print(\"Permutation Feature Importance for KNN\")\n",
        "knn_pfi = run_pfi(knn_model, X_test_transformed, y_test, feature_names, model_name=\"KNN\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzYcq9FnQWls"
      },
      "source": [
        "# PFI for XG-Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znlGreyTQIeD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "dcaeeb7e-32ae-45c3-cceb-fa4d57a81e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Permutation Feature Importance for XGBoost\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'run_pfi' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1021771148.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Permutation Feature Importance for XGBoost\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf_pfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_pfi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"XGBoost\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'run_pfi' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"Permutation Feature Importance for XGBoost\")\n",
        "rf_pfi = run_pfi(xgb_model, X_test_transformed, y_test, feature_names, model_name=\"XGBoost\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpBH4l1vQM3-"
      },
      "source": [
        "# PFI for Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww1up1MGQMWU"
      },
      "outputs": [],
      "source": [
        "print(\"Permutation Feature Importance for Multi-Layer Perception\")\n",
        "rf_pfi = run_pfi(mlp_model, X_test_transformed, y_test, feature_names, model_name=\"MLP\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ8NkluDSA-o"
      },
      "source": [
        "# PDP/ICE Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBXkjqtwYXs9"
      },
      "outputs": [],
      "source": [
        "def plot_pdp_ice_all_numeric_safe(pipeline, X_train, model_name, features):\n",
        "    #Get feature names from training data\n",
        "    raw_feature_names = list(X_train.columns)\n",
        "\n",
        "    for feature in features:            #Skip if feature is not in the dataset\n",
        "        if feature not in raw_feature_names:\n",
        "            print(f\"Feature '{feature}' not found in X_train columns!\")\n",
        "            continue\n",
        "\n",
        "        feature_idx = raw_feature_names.index(feature)\n",
        "        unique_vals = np.unique(X_train[feature])\n",
        "\n",
        "        print(f\"Generating PDP for '{feature}' ({model_name})...\")\n",
        "\n",
        "        if len(unique_vals) <= 4:\n",
        "            #PDP for binary/categorical features\n",
        "            probs = []\n",
        "            for val in unique_vals:\n",
        "                X_copy = X_train.copy()\n",
        "                X_copy[feature] = val\n",
        "                preds = pipeline.predict_proba(X_copy)[:, 1]  #probability for class 1\n",
        "                probs.append(np.mean(preds))\n",
        "\n",
        "            plt.bar([str(v) for v in unique_vals], probs)\n",
        "            plt.xlabel(feature)\n",
        "            plt.ylabel(\"Predicted Probability\")\n",
        "            plt.title(f\"{model_name} - PDP for {feature} (categorical/binary)\")\n",
        "            plt.show()\n",
        "\n",
        "        else:\n",
        "            #PDP an ICE for continuous features\n",
        "            PartialDependenceDisplay.from_estimator(\n",
        "                pipeline,\n",
        "                X_train,\n",
        "                [feature_idx],\n",
        "                kind='both',                #PDP + ICE\n",
        "                subsample=50,\n",
        "                random_state=42,\n",
        "                response_method='predict_proba'\n",
        "            )\n",
        "            plt.title(f\"{model_name} - PDP + ICE for {feature} (continuous)\")\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUPJQ0jlSO_S"
      },
      "source": [
        "# PDP/ICE for RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKraWauiYavP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "fe0e6279-c6b4-4ff0-edaf-b4095e480183"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plot_pdp_ice_all_numeric_safe' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4171183898.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#For Random Forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m plot_pdp_ice_all_numeric_safe(results[\"Random Forest\"][\"pipeline\"],\n\u001b[0m\u001b[1;32m      5\u001b[0m                               \u001b[0mX_train_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0;34m\"Random Forest\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_pdp_ice_all_numeric_safe' is not defined"
          ]
        }
      ],
      "source": [
        "top_7_features = ['cp', 'chol', 'age', 'ca', 'thal', 'exang', 'thalach']\n",
        "\n",
        "#For Random Forest\n",
        "plot_pdp_ice_all_numeric_safe(results[\"Random Forest\"][\"pipeline\"],\n",
        "                              X_train_raw,\n",
        "                              \"Random Forest\",\n",
        "                              top_7_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYwFFgujwiJ_"
      },
      "source": [
        "# sex\n",
        "The model predicts a higher probability of heart disease for Females(~0.59)\n",
        "compared to Males (~0.51). The model associates Females with higher average risk.\n",
        "\n",
        "# exang\n",
        "The model shows, given the rest of the features, patients who do not experience exercise-induced angina tend to have a slightly higher predicted risk of heart disease than those who do.\n",
        "\n",
        "# slope\n",
        "Downsloping (slope=2) is associated with the highest predicted probability (~0.57).\n",
        "\n",
        "Flat (slope=1) and Upsloping (slope=0) have slightly lower predicted risks (~0.52–0.53).\n",
        "\n",
        "This suggests the model sees downsloping ST segments as a stronger indicator of heart disease risk.\n",
        "\n",
        "#thal\n",
        "The model predicts highest risk (~0.59–0.60) for categories 2 and slightly lower for 0/1.\n",
        "\n",
        "The lowest risk (~0.45) is predicted for category 3.\n",
        "\n",
        "This indicates the model views thal=2 (likely a reversible defect) as the strongest risk indicator, while thal=3 is the least associated with heart disease.\n",
        "\n",
        "#oldpeak\n",
        "The average predicted risk starts higher (~0.6) when oldpeak is near 0, then declines as oldpeak increases up to ~3, after which it stabilizes.\n",
        "\n",
        "This trend suggests the model predicts lower heart disease probability as ST depression increases, which may reflect dataset-specific patterns or feature interaction.\n",
        "\n",
        "The ICE curves show high variability, with some predictions dropping sharply and others staying high, indicating heterogeneous effects across individuals.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g4FwKDmSbey"
      },
      "source": [
        "# PDP/ICE for KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-yugGWWgyIq"
      },
      "outputs": [],
      "source": [
        "top_7_features = ['cp', 'chol', 'age', 'sex', 'thal', 'exang', 'thalach']\n",
        "\n",
        "#For KNN\n",
        "plot_pdp_ice_all_numeric_safe(results[\"KNN\"][\"pipeline\"],\n",
        "                              X_train_raw,\n",
        "                              \"KNN\",\n",
        "                              top_7_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okg_XmYk3Yji"
      },
      "source": [
        "# sex\n",
        "The average predicted probability of heart disease is higher (~0.65) for individuals females, compared to ~0.50 for males.\n",
        "\n",
        "The KNN model is using sex as a strong differentiator in its predictions, with a noticeable gap in risk between the two groups.\n",
        "\n",
        "# exang\n",
        "The average predicted probability of heart disease is higher (~0.59) for people with no exercise-induced angina and lower (~0.49) for presence of angina.\n",
        "\n",
        "The KNN model sees no angina as linked to higher predicted risk.\n",
        "\n",
        "# slope\n",
        "The model predicts a clear increase in risk as the slope category shifts toward more abnormal ST segments\n",
        "\n",
        "# thal\n",
        "The average predicted probability of heart disease is highest (~0.65) for thal=1, slightly lower for thal=0, and then decreases for thal=2 and most noticeably for thal=3 (~0.50).\n",
        "\n",
        "The KNN model treats thal as a risk-differentiating factor, with thal=1 (likely fixed defect) linked to the greatest predicted risk, while thal=3 corresponds to the lowest.\n",
        "\n",
        "These differences suggest the model views certain thalassemia categories (particularly thal=1) as strong indicators of higher heart disease risk, likely reflecting patterns in the training dataset rather than a direct causal effect.\n",
        "\n",
        "# oldpeak\n",
        "The average predicted probability of heart disease (dashed line) is highest (~0.6) when oldpeak is near 0 and declines steadily as oldpeak increases, dropping below 0.3 around 6.\n",
        "\n",
        "This trend implies the KNN model predicts lower heart disease risk at higher ST depression values, which may reflect dataset-specific patterns or interactions with other features rather than a direct causal link.\n",
        "\n",
        "The ICE curves show significant variability — some patients’ predicted risks remain high while others drop sharply, suggesting strong interactions between oldpeak and other factors in the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUsST1T8VEgD"
      },
      "source": [
        "# PDP/ICE for XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saZ80MloVESc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "82d5bf21-7ced-4f3a-d9aa-ed418336e5fb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plot_pdp_ice_all_numeric_safe' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2566585310.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#For XGBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m plot_pdp_ice_all_numeric_safe(results[\"XGBoost\"][\"pipeline\"],\n\u001b[0m\u001b[1;32m      5\u001b[0m                               \u001b[0mX_train_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0;34m\"XGBoost\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_pdp_ice_all_numeric_safe' is not defined"
          ]
        }
      ],
      "source": [
        "top_7_features =['cp', 'chol', 'age', 'sex', 'thal', 'ca', 'thalach']\n",
        "\n",
        "#For XGBoost\n",
        "plot_pdp_ice_all_numeric_safe(results[\"XGBoost\"][\"pipeline\"],\n",
        "                              X_train_raw,\n",
        "                              \"XGBoost\",\n",
        "                              top_7_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2q_Q5aGVbGE"
      },
      "source": [
        "# PDP/ICE for Multi-Layer Perpetualtion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Idho3A6VZnk"
      },
      "outputs": [],
      "source": [
        "top_7_features = ['cp', 'chol', 'age', 'sex', 'ca', 'slope', 'thalach']\n",
        "\n",
        "\n",
        "#For KNN\n",
        "plot_pdp_ice_all_numeric_safe(results[\"MLP\"][\"pipeline\"],\n",
        "                              X_train_raw,\n",
        "                              \"MLP\",\n",
        "                              top_7_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl4cO60A8taq"
      },
      "source": [
        "# Counterfactuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbOq_XkhN8H_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "929f7698-fe5e-4457-a4af-db49ed9b4d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Counterfactuals for Random Forest ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1558301542.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Random Forest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"KNN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"XGBoost\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MLP\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n=== Counterfactuals for {model} ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_counterfactuals_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_CFs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1558301542.py\u001b[0m in \u001b[0;36mgenerate_counterfactuals_for_model\u001b[0;34m(model_name, sample_idx, total_CFs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_counterfactuals_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_CFs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model '{model_name}' not found. Available: {list(results.keys())}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ],
      "source": [
        "def generate_counterfactuals_for_model(model_name, sample_idx=43, total_CFs=3):\n",
        "\n",
        "    if model_name not in results:\n",
        "        raise ValueError(f\"Model '{model_name}' not found. Available: {list(results.keys())}\")\n",
        "\n",
        "    #Combine train features and target\n",
        "    data = X_train_raw.copy()\n",
        "    data['target'] = y_train.values\n",
        "\n",
        "    #Define continuous and categorical features\n",
        "    continuous_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "    categorical_features = [col for col in X_train_raw.columns if col not in continuous_features]\n",
        "\n",
        "    #  Create DiCE data interface\n",
        "    dice_data = dice_ml.Data(\n",
        "        dataframe=data,\n",
        "        continuous_features=continuous_features,\n",
        "        outcome_name='target'\n",
        "    )\n",
        "\n",
        "    #Wrap pipeline for DiCE\n",
        "    pipeline = results[model_name][\"pipeline\"]\n",
        "    dice_model = dice_ml.Model(model=pipeline, backend=\"sklearn\")\n",
        "\n",
        "    #create the DiCE explainer\n",
        "    exp = Dice(data_interface=dice_data, model_interface=dice_model, method=\"genetic\")\n",
        "\n",
        "    #Select the patient to generate counterfactuals for\n",
        "    sample = X_test_raw.iloc[[sample_idx]]\n",
        "    print(f\"\\nOriginal model prediction ({model_name}):\", pipeline.predict(sample))\n",
        "\n",
        "    # Generate counterfactuals\n",
        "    counterfactuals = exp.generate_counterfactuals(\n",
        "        sample,\n",
        "        total_CFs=total_CFs,\n",
        "        desired_class=\"opposite\",  #flip 0→1 or 1→0\n",
        "    )\n",
        "\n",
        "\n",
        "    #Show results\n",
        "    return counterfactuals.visualize_as_dataframe()\n",
        "\n",
        "#Generate for each model\n",
        "for model in [\"Random Forest\", \"KNN\", \"XGBoost\", \"MLP\"]:\n",
        "    print(f\"\\n=== Counterfactuals for {model} ===\")\n",
        "    display(generate_counterfactuals_for_model(model, sample_idx=43, total_CFs=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvHWVeNywJ3g"
      },
      "source": [
        "**Random Forest**\n",
        "1. The model is very sensitive to age, chol, and trestbps for this patient.\n",
        "\n",
        "2. By reducing age and slightly modifying blood pressure and cholesterol, the predicted risk drops enough to flip from 1 (disease) to 0 (no disease).\n",
        "\n",
        "3. All other features (sex, cp, thalach, thal, etc.) remain unchanged because:\n",
        "\n",
        "* We locked them (not allowed to vary), or\n",
        "\n",
        "* The model doesn’t rely on them as heavily for this patient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky_E2u1e-gIe"
      },
      "source": [
        "# Surrogate Model (Decision Tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ORO-1Ai-fYk"
      },
      "outputs": [],
      "source": [
        "#Change model here\n",
        "blackbox_model_name = \"MLP\" #Random Forest, KNN, XGBoost, MLP\n",
        "\n",
        "#get model and its pipeline\n",
        "blackbox_pipeline = results[blackbox_model_name][\"pipeline\"]\n",
        "blackbox_model = blackbox_pipeline.named_steps[\"classifier\"]\n",
        "preprocessor = blackbox_pipeline.named_steps[\"preprocessor\"]\n",
        "\n",
        "#Preprocess the training data\n",
        "X_train_processed = preprocessor.transform(X_train_raw)\n",
        "\n",
        "#get the predicted class labels\n",
        "y_pred_blackbox_classes = blackbox_model.predict(X_train_processed)\n",
        "\n",
        "# Train surrogate on processed training data and b-b predicted classes\n",
        "surrogate = DecisionTreeClassifier(max_depth=4, random_state=42)  # limit depth for simplicity\n",
        "surrogate.fit(X_train_processed, y_pred_blackbox_classes)\n",
        "\n",
        "\n",
        "#Print the tree's rules\n",
        "#feature names after preprocessing\n",
        "feature_names_processed = preprocessor.get_feature_names_out()\n",
        "tree_rules = export_text(surrogate, feature_names=list(feature_names_processed))\n",
        "print(\"Surrogate Decision Tree Rules:\")\n",
        "print(tree_rules)\n",
        "\n",
        "#Visualize tree\n",
        "plt.figure(figsize=(20, 10)) # Increased figure size for better visibility\n",
        "plot_tree(surrogate, feature_names=feature_names_processed, class_names=[\"No Disease\", \"Disease\"], filled=True, fontsize=10)\n",
        "plt.title(f\"Surrogate Decision Tree for {blackbox_model_name} (max_depth=4)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKqH0f-ZHidq"
      },
      "source": [
        "# Aggregation of Local -> Global"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwfW-5sj_aOh"
      },
      "outputs": [],
      "source": [
        "############################### LIME #####################################\n",
        "k = 61  #Number of instances to analyze\n",
        "lime_feature_counts = {}\n",
        "\n",
        "#Extract trained pipeline parts\n",
        "rf_pipeline = results[\"XGBoost\"][\"pipeline\"]\n",
        "preprocessor = rf_pipeline.named_steps[\"preprocessor\"]\n",
        "rf_model = rf_pipeline.named_steps[\"classifier\"]\n",
        "\n",
        "#Preprocess\n",
        "X_train_processed = preprocessor.transform(X_train_raw)\n",
        "\n",
        "#LIME explainer\n",
        "explainer = LimeTabularExplainer(\n",
        "    training_data=X_train_processed,\n",
        "    feature_names=preprocessor.get_feature_names_out(),\n",
        "    class_names=['No Disease', 'Heart Disease'],\n",
        "    mode='classification',\n",
        "    discretize_continuous=True\n",
        ")\n",
        "\n",
        "def rf_predict_proba(x):\n",
        "    return rf_model.predict_proba(x)\n",
        "\n",
        "#Loop through k instances in test set\n",
        "for i in range(k):\n",
        "    X_one_raw = X_test_raw.iloc[[i]]\n",
        "    X_one_transformed = preprocessor.transform(X_one_raw)\n",
        "\n",
        "    #Explain one instance\n",
        "    lime_exp = explainer.explain_instance(\n",
        "        data_row=X_one_transformed[0],\n",
        "        predict_fn=rf_predict_proba,\n",
        "        num_features=7\n",
        "    )\n",
        "\n",
        "    #Collect feature importance\n",
        "    for feature, weight in lime_exp.as_list():\n",
        "        if feature not in lime_feature_counts:\n",
        "            lime_feature_counts[feature] = 0\n",
        "        lime_feature_counts[feature] += 1\n",
        "\n",
        "#Sort and print most frequently important features\n",
        "sorted_features = sorted(lime_feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(f\"\\nTop features from LIME - across {k} instances:\")\n",
        "for feature, count in sorted_features:\n",
        "    print(f\"{feature}: {count} times\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ltNPR0vaZ-9"
      },
      "outputs": [],
      "source": [
        "################################## Counterfactuals #####################################\n",
        "cf_feature_counts = {}\n",
        "\n",
        "#trained MLmodel pipeline\n",
        "rf_pipeline = results[\"Random Forest\"][\"pipeline\"]\n",
        "preprocessor = rf_pipeline.named_steps[\"preprocessor\"]\n",
        "rf_model = rf_pipeline.named_steps[\"classifier\"]\n",
        "\n",
        "#Prepare data for DiCE\n",
        "data = X_train_raw.copy()\n",
        "data['target'] = y_train.values\n",
        "\n",
        "continuous_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "categorical_features = [col for col in X_train_raw.columns if col not in continuous_features]\n",
        "\n",
        "dice_data = dice_ml.Data(\n",
        "    dataframe=data,\n",
        "    continuous_features=continuous_features,\n",
        "    outcome_name='target'\n",
        ")\n",
        "\n",
        "dice_model = dice_ml.Model(model=rf_pipeline, backend=\"sklearn\") # Use the full pipeline-\n",
        "\n",
        "#Create the DiCE explainer\n",
        "dice_explainer = Dice(data_interface=dice_data, model_interface=dice_model, method=\"genetic\")\n",
        "\n",
        "\n",
        "for i in range(61):\n",
        "    # Get the instance\n",
        "    query_instance = X_test_raw.iloc[i:i+1]\n",
        "\n",
        "    try:\n",
        "        #Generate counterfactuals\n",
        "        cf = dice_explainer.generate_counterfactuals(\n",
        "          query_instance,\n",
        "          total_CFs=1,\n",
        "          desired_class=\"opposite\"\n",
        "          )\n",
        "\n",
        "        #FIX ERROR\n",
        "        #did CF generated successfully\n",
        "        if cf and cf.cf_examples_list and len(cf.cf_examples_list) > 0 and cf.cf_examples_list[0].final_cfs_df is not None:\n",
        "            cf_df = cf.cf_examples_list[0].final_cfs_df\n",
        "\n",
        "            #Compare instance and counterfactual\n",
        "            for col in query_instance.columns:\n",
        "                original = query_instance[col].values[0]\n",
        "                counterfactual = cf_df[col].values[0]\n",
        "\n",
        "                if original != counterfactual:\n",
        "                    #Count the changed feature\n",
        "                    if col not in cf_feature_counts:\n",
        "                        cf_feature_counts[col] = 0\n",
        "                    cf_feature_counts[col] += 1\n",
        "        else:\n",
        "            print(f\"Could not generate counterfactuals for instance {i}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating counterfactuals for instance {i}: {e}\")\n",
        "\n",
        "\n",
        "#Sort and display\n",
        "sorted_cf_features = sorted(cf_feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nTop features changed in Counterfactuals across 61 instances:\")\n",
        "for feature, count in sorted_cf_features:\n",
        "    print(f\"{feature}: {count} times\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RBO"
      ],
      "metadata": {
        "id": "2zPYIRvX1ewW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rbo_truncated(list_a, list_b, p=0.9, k=None):\n",
        "    #truncated RBO calculation up to depth k\n",
        "    if k is None:\n",
        "        k = min(len(list_a), len(list_b))\n",
        "    seen_a, seen_b = set(), set()\n",
        "    s = 0.0\n",
        "    for d in range(1, k + 1):\n",
        "        seen_a.add(list_a[d-1])\n",
        "        seen_b.add(list_b[d-1])\n",
        "        overlap_d = len(seen_a & seen_b)  #overlap at depth d\n",
        "        A_d = overlap_d / d                #agreement ratio\n",
        "        s += (p ** (d - 1)) * A_d          #weighted sum\n",
        "    return s, A_d\n",
        "\n",
        "\n",
        "def rbo_full_from_truncated(raw_sum, A_k, p=0.9, k=7):\n",
        "    #Complete RBO with infinite tail correction\n",
        "    return (1 - p) * (raw_sum + (A_k * (p ** k)) / (1 - p))\n",
        "\n",
        "\n",
        "#Edit as needed\n",
        "expert_top7 = [\"num__cp\",\"num__chol\",\"num__trestbps\",\"num__fbs\",\"num__exang\",\"num__age\",\"num__sex\"]\n",
        "model_top7  = [\"num__cp\",\"num__chol\",\"num__age\",\"num__sex\",\"num__ca\",\"num__slope\",\"num__thalach\"]\n",
        "\n",
        "p = 0.9\n",
        "\n",
        "features = [f for f in df.columns if f != \"target\"] #Exclude target column\n",
        "\n",
        "#truncated raw sum + last agreement\n",
        "raw_sum, A_k = rbo_truncated(expert_top7, model_top7, p, k=7)\n",
        "\n",
        "#compute RBO, normalized\n",
        "full_rbo = rbo_full_from_truncated(raw_sum, A_k, p, k=7)\n",
        "\n",
        "print(\"Truncated RBO:\", round((1 - p) * raw_sum, 3))\n",
        "print(\"Full RBO:\", round(full_rbo, 3))\n",
        "\n"
      ],
      "metadata": {
        "id": "LjeF70bS1lkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Similarity"
      ],
      "metadata": {
        "id": "DvEr5z9k1Prd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cumulative Sum values for each model\n",
        "rf_data = {\n",
        "    \"LIME_RF\": [0, 0, 0, 0, 0.013122, 0.0426465, 0.0654225],\n",
        "    \"SHAP_RF\": [0.1, 0.145, 0.172, 0.190255, 0.203347, 0.211388, 0.220781],\n",
        "    \"PFI_RF\": [0, 0, 0, 0, 0, 0.009842, 0.02502],\n",
        "    \"PDP_RF\": [0.1, 0.19, 0.244, 0.2804, 0.306969, 0.346065, 0.376472],\n",
        "    \"Counterfactuals_RF\": [0, 0, 0.027, 0.06345, 0.089694, 0.12906, 0.159428],\n",
        "    \"Surrogate_RF\": [0.1, 0.145, 0.172, 0.190225, 0.203347, 0.22303, 0.245806]\n",
        "}\n",
        "\n",
        "knn_data = {\n",
        "    \"LIME_KNN\": [0, 0, 0, 0, 0.026244, 0.045927, 0.061111],\n",
        "    \"SHAP_KNN\": [0, 0, 0, 0.018225, 0.044469, 0.064152, 0.08693],\n",
        "    \"PFI_KNN\": [0, 0, 0, 0, 0, 0.053144, 0.053144],\n",
        "    \"PDP_KNN\": [0.1, 0.19, 0.244, 0.2804, 0.30669, 0.33621, 0.366616],\n",
        "    \"Counterfactuals_KNN\": [0, 0.045, 0.072, 0.10845, 0.13469, 0.17406, 0.20442],\n",
        "    \"Surrogate_KNN\": [0.1, 0.145, 0.172, 0.190225, 0.216469, 0.236152, 0.258928]\n",
        "}\n",
        "\n",
        "xgb_data = {\n",
        "    \"LIME_XGB\": [0, 0, 0, 0.018225, 0.031347, 0.05103, 0.073806],\n",
        "    \"SHAP_XGB\": [0.1, 0.145, 0.172, 0.190225, 0.216469, 0.236152, 0.258951],\n",
        "    \"PFI_XGB\": [0, 0, 0, 0, 0.00984, 0.02502, 0.02502],\n",
        "    \"PDP_XGB\": [0.1, 0.19, 0.244, 0.2804, 0.30669, 0.33621, 0.36661],\n",
        "    \"Counterfactuals_XGB\": [0, 0.045, 0.072, 0.10845, 0.134694, 0.17406, 0.204428],\n",
        "    \"Surrogate_XGB\": [0.1, 0.145, 0.172, 0.190225, 0.203347, 0.213188, 0.228373]\n",
        "}\n",
        "\n",
        "mlp_data = {\n",
        "    \"LIME_MLP\": [0, 0, 0, 0.018225, 0.031347, 0.05103, 0.073806],\n",
        "    \"SHAP_MLP\": [0.1, 0.145, 0.172, 0.190225, 0.216469, 0.236152, 0.258951],\n",
        "    \"PFI_MLP\": [0, 0, 0, 0, 0.00984, 0.02502, 0.02502],\n",
        "    \"PDP_MLP\": [0.1, 0.19, 0.244, 0.2804, 0.30669, 0.33621, 0.36661],\n",
        "    \"Counterfactuals_MLP\": [0, 0.045, 0.072, 0.10845, 0.134694, 0.17406, 0.204428],\n",
        "    \"Surrogate_MLP\": [0.1, 0.145, 0.172, 0.190225, 0.203347, 0.213188, 0.228373]\n",
        "}\n",
        "\n",
        "# Function to compute cosine similarity and Spearman correlation\n",
        "def compute_similarity(df):\n",
        "\n",
        "    #Cosine\n",
        "    cosine_sim = cosine_similarity(df.T)\n",
        "    cosine_df = pd.DataFrame(cosine_sim, index=df.columns, columns=df.columns)\n",
        "\n",
        "    #Spearman\n",
        "    methods = df.columns\n",
        "    spearman_matrix = pd.DataFrame(index=methods, columns=methods, dtype=float)\n",
        "    for i in methods:\n",
        "        for j in methods:\n",
        "            rho, _ = spearmanr(df[i], df[j])\n",
        "            spearman_matrix.loc[i, j] = rho\n",
        "\n",
        "    return cosine_df, spearman_matrix\n",
        "\n",
        "# Run for all models\n",
        "with pd.ExcelWriter(\"Vector_Similarity_All_Models.xlsx\") as writer: #Save results to Excel\n",
        "    for model_name, model_data in {\n",
        "        \"RF\": rf_data,\n",
        "        \"KNN\": knn_data,\n",
        "        \"XGB\": xgb_data,\n",
        "        \"MLP\": mlp_data\n",
        "    }.items():\n",
        "        df = pd.DataFrame(model_data)\n",
        "        cosine_df, spearman_matrix = compute_similarity(df)\n",
        "\n",
        "        #2 separate excel sheets\n",
        "        cosine_df.to_excel(writer, sheet_name=f\"{model_name}_Cosine\")\n",
        "        spearman_matrix.to_excel(writer, sheet_name=f\"{model_name}_Spearman\")\n",
        "\n",
        "print(\"Similarity matrices saved\")\n"
      ],
      "metadata": {
        "id": "N-vj6ED21cB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time/Space"
      ],
      "metadata": {
        "id": "dioyDln2IN7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "performance_results = []\n",
        "\n",
        "def lime_explainer(pipeline, X):\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    explainer = LimeTabularExplainer(\n",
        "        training_data=preprocessor.transform(X_train_raw),   #background from training set\n",
        "        feature_names=preprocessor.get_feature_names_out(),  #names after preprocessing\n",
        "        class_names=['No Disease', 'Heart Disease'],\n",
        "        mode='classification'\n",
        "    )\n",
        "    #explain one instance\n",
        "    _ = explainer.explain_instance(\n",
        "        data_row=preprocessor.transform(X.iloc[[0]])[0],\n",
        "        predict_fn=model.predict_proba,\n",
        "        num_features=7\n",
        "    )\n",
        "\n",
        "def shap_explainer(pipeline, X):\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    X_proc = preprocessor.transform(X)\n",
        "    explainer = shap.Explainer(model.predict, X_proc)\n",
        "    # run on first 10 samples\n",
        "    _ = explainer(X_proc[:10])\n",
        "\n",
        "def pfi_explainer(pipeline, X, y):\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    X_proc = preprocessor.transform(X)\n",
        "    _ = permutation_importance(model, X_proc, y, n_repeats=5)\n",
        "\n",
        "def pdp_explainer(pipeline, X):\n",
        "    #average effect of features (first 5 features only)\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    X_proc = preprocessor.transform(X)\n",
        "    features = list(range(min(5, X_proc.shape[1]))) #first 5 features only\n",
        "    PartialDependenceDisplay.from_estimator(model, X_proc, features)\n",
        "\n",
        "def counterfactual_explainer(pipeline, X):\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    X_proc = preprocessor.transform(X)\n",
        "    d = dice_ml.Data(\n",
        "        dataframe=pd.concat([X_train_raw, y_train], axis=1),\n",
        "        continuous_features=X_train_raw.columns.tolist(),\n",
        "        outcome_name=y_train.name\n",
        "    )\n",
        "    m = dice_ml.Model(model=model, backend=\"sklearn\")\n",
        "    exp = dice_ml.Dice(d, m)\n",
        "    _ = exp.generate_counterfactuals(X_train_raw.iloc[[0]], total_CFs=1)\n",
        "\n",
        "def surrogate_explainer(pipeline, X):\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    X_proc = preprocessor.transform(X)\n",
        "    y_pred = model.predict(X_proc)\n",
        "    surrogate = DecisionTreeClassifier(max_depth=3)\n",
        "    surrogate.fit(X_proc, y_pred)\n",
        "\n",
        "#Connect names to functions\n",
        "xai_methods = {\n",
        "    \"LIME\": lambda p, X: lime_explainer(p, X),\n",
        "    \"SHAP\": lambda p, X: shap_explainer(p, X),\n",
        "    \"PFI\": lambda p, X: pfi_explainer(p, X, y_test),\n",
        "    \"PDP\": lambda p, X: pdp_explainer(p, X),\n",
        "    \"Counterfactuals\": lambda p, X: counterfactual_explainer(p, X),\n",
        "    \"Surrogate\": lambda p, X: surrogate_explainer(p, X)\n",
        "}\n",
        "\n",
        "  #run performance tests and measure time/memory for each model and method combo\n",
        "for model_name, model_data in results.items():\n",
        "    pipeline = model_data[\"pipeline\"]\n",
        "    for method_name, method_func in xai_methods.items():\n",
        "        print(f\"Running {method_name} for {model_name}...\")\n",
        "        start_time = time.perf_counter()     #start timer\n",
        "        tracemalloc.start()                  #start memory tracking\n",
        "        try:\n",
        "            method_func(pipeline, X_test_raw)   #run explainer\n",
        "        except Exception as e:\n",
        "            print(f\" ERROR with {method_name} for {model_name}: {e}\")\n",
        "        current, peak = tracemalloc.get_traced_memory()  #peak memory usage\n",
        "        tracemalloc.stop()\n",
        "        end_time = time.perf_counter()     #end timer\n",
        "\n",
        "        #Store results\n",
        "        performance_results.append({\n",
        "            \"Model\": model_name,\n",
        "            \"Method\": method_name,\n",
        "            \"Time_sec\": round(end_time - start_time, 4),\n",
        "            \"Peak_MB\": round(peak / (1024 * 1024), 4)\n",
        "        })\n",
        "\n",
        "\n",
        "#Save results in Excel\n",
        "df_perf = pd.DataFrame(performance_results)\n",
        "df_perf.to_excel(\"Performance_Results.xlsx\", index=False)\n",
        "print(\"Performance metrics saved\")\n"
      ],
      "metadata": {
        "id": "VHruLOZ8IKC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time plot\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "sns.barplot(        #Barplot for each method across models\n",
        "    data=df_perf,\n",
        "    x=\"Method\",\n",
        "    y=\"Time_sec\",\n",
        "    hue=\"Model\",\n",
        "    palette=\"Set2\"\n",
        ")\n",
        "plt.title(\"XAI Runtime Performance\")\n",
        "plt.ylabel(\"Execution Time (seconds)\")\n",
        "plt.xlabel(\"XAI Method\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.legend(title=\"Model\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Memory plot ---\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(\n",
        "    data=df_perf,\n",
        "    x=\"Method\",\n",
        "    y=\"Peak_MB\",\n",
        "    hue=\"Model\",\n",
        "    palette=\"Set2\"\n",
        ")\n",
        "plt.title(\"XAI Memory Usage Performance\")\n",
        "plt.ylabel(\"Peak Memory (MB)\")\n",
        "plt.xlabel(\"XAI Method\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.legend(title=\"Model\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-wHJpG_AIRuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONoT-fLvBEIC"
      },
      "source": [
        "# Stability test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lime_stability(pipeline, X):\n",
        "    #get feature weights for one instance\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    explainer = LimeTabularExplainer(\n",
        "        training_data=preprocessor.transform(X_train_raw),\n",
        "        feature_names=preprocessor.get_feature_names_out(),\n",
        "        class_names=['No Disease', 'Heart Disease'],\n",
        "        mode='classification'\n",
        "    )\n",
        "    exp = explainer.explain_instance(\n",
        "        data_row=preprocessor.transform(X.iloc[[0]])[0],\n",
        "        predict_fn=model.predict_proba,\n",
        "        num_features=7\n",
        "    )\n",
        "    #Convert explanation to a vector aligned with feature names\n",
        "    weights = dict(exp.as_list())\n",
        "    return np.array([weights.get(f, 0) for f in preprocessor.get_feature_names_out()])\n",
        "\n",
        "\n",
        "def shap_stability(pipeline, X):\n",
        "    #average absolute shap values across 10 samples\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    X_proc = preprocessor.transform(X)\n",
        "    explainer = shap.Explainer(model.predict, X_proc)\n",
        "    shap_values = explainer(X_proc[:10])\n",
        "    return np.mean(np.abs(shap_values.values), axis=0)\n",
        "\n",
        "\n",
        "def pfi_stability(pipeline, X, y):\n",
        "    #mean score across runs\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    X_proc = preprocessor.transform(X)\n",
        "    r = permutation_importance(model, X_proc, y, n_repeats=5)\n",
        "    return r.importances_mean\n",
        "\n",
        "\n",
        "def pdp_stability(pipeline, X):\n",
        "    #use the variance of PDP curve as a proxy for feature stability\n",
        "    from sklearn.inspection import partial_dependence\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    X_proc = preprocessor.transform(X)\n",
        "    features = list(range(min(5, X_proc.shape[1])))\n",
        "    pdp_vals = []\n",
        "    for f in features:\n",
        "        pdp_result = partial_dependence(model, X_proc, [f])\n",
        "        pdp_vals.append(np.var(pdp_result.average))\n",
        "    return np.array(pdp_vals)\n",
        "\n",
        "\n",
        "def counterfactuals_stability(pipeline, X):\n",
        "    #mark which features change between instance and CF\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    d = dice_ml.Data(\n",
        "        dataframe=pd.concat([X_train_raw, y_train], axis=1),\n",
        "        continuous_features=X_train_raw.columns.tolist(),\n",
        "        outcome_name=y_train.name\n",
        "    )\n",
        "    m = dice_ml.Model(model=model, backend=\"sklearn\")\n",
        "    exp = dice_ml.Dice(d, m)\n",
        "    cf = exp.generate_counterfactuals(X_train_raw.iloc[[0]], total_CFs=1)\n",
        "    changed = cf.cf_examples_list[0].final_cfs_df.iloc[0] != X_train_raw.iloc[0]\n",
        "    return changed.astype(int).values\n",
        "\n",
        "\n",
        "def surrogate_stability(pipeline, X):\n",
        "    #fit a decision tree and return feature importances\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    preprocessor = pipeline.named_steps[\"preprocessor\"]\n",
        "    model = pipeline.named_steps[\"classifier\"]\n",
        "    X_proc = preprocessor.transform(X)\n",
        "    y_pred = model.predict(X_proc)\n",
        "    surrogate = DecisionTreeClassifier(max_depth=3)\n",
        "    surrogate.fit(X_proc, y_pred)\n",
        "    return surrogate.feature_importances_\n",
        "\n",
        "#Connect names to functions\n",
        "xai_methods_stability = {\n",
        "    \"LIME\": lambda p, X: lime_stability(p, X),\n",
        "    \"SHAP\": lambda p, X: shap_stability(p, X),\n",
        "    \"PFI\": lambda p, X: pfi_stability(p, X, y_test),\n",
        "    \"PDP\": lambda p, X: pdp_stability(p, X),\n",
        "    \"Counterfactuals\": lambda p, X: counterfactuals_stability(p, X),\n",
        "    \"Surrogate\": lambda p, X: surrogate_stability(p, X)\n",
        "}\n"
      ],
      "metadata": {
        "id": "u7Tord2LxK2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stability_results = []\n",
        "\n",
        "repeats = 5  # number of times to repeat explanation\n",
        "#Loop thru each model and XAI method\n",
        "for model_name, model_data in results.items():\n",
        "    pipeline = model_data[\"pipeline\"]\n",
        "    for method_name, method_func in xai_methods_stability.items():\n",
        "        all_runs = []\n",
        "\n",
        "        for _ in range(repeats):               #repeat explanations multiple times\n",
        "            try:\n",
        "                vec = method_func(pipeline, X_test_raw) #numeric vector from method\n",
        "                all_runs.append(vec)\n",
        "            except Exception as e:\n",
        "                print(f\"{method_name} failed for {model_name}: {e}\")\n",
        "                break\n",
        "        if all_runs:\n",
        "            arr = np.vstack(all_runs)       #stack results from all runs\n",
        "            mean_val = np.mean(arr)         #mean stability score\n",
        "            std_val = np.std(arr)           #std dev of stability score\n",
        "            stability_results.append({\n",
        "                \"Model\": model_name,\n",
        "                \"Method\": method_name,\n",
        "                \"Mean\": mean_val,\n",
        "                \"StdDev\": std_val\n",
        "            })\n",
        "#Save in excel\n",
        "df_stability = pd.DataFrame(stability_results)\n",
        "df_stability.to_excel(\"Stability_Results.xlsx\", index=False)\n",
        "print(\"Stability results saved\")\n"
      ],
      "metadata": {
        "id": "n3wrCOSt5ugM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "a323a553-6e0a-492a-8631-391c529e1958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2175031551.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrepeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m  \u001b[0;31m# number of times to repeat explanation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Loop thru each model and XAI method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pipeline\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxai_methods_stability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VISUALIZATION OF STABILITY\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(\n",
        "    data=df_stability,\n",
        "    x=\"Method\",\n",
        "    y=\"Mean\",\n",
        "    hue=\"Model\",\n",
        "    palette=\"Set2\",\n",
        "    capsize=0.1,\n",
        "    errwidth=1,\n",
        "    ci=None\n",
        ")\n",
        "\n",
        "#Add error bars manually from StdDev\n",
        "for i, row in df_stability.iterrows():\n",
        "    plt.errorbar(\n",
        "        x=i % len(df_stability['Method'].unique()),  #position within group\n",
        "        y=row['Mean'],\n",
        "        yerr=row['StdDev'],\n",
        "        fmt='none',\n",
        "        c='black',\n",
        "        capsize=5\n",
        "    )\n",
        "\n",
        "plt.title(\"Stability Robustness of XAI Methods (Mean ± Std Dev)\")\n",
        "plt.ylabel(\"Stability Score\")\n",
        "plt.xlabel(\"XAI Method\")\n",
        "plt.legend(title=\"Model\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TDUFtfJbD4YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T-SNE"
      ],
      "metadata": {
        "id": "xjhcMnWA3Fsn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "du9cnp1cjzse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fidility"
      ],
      "metadata": {
        "id": "Qw_6COsSaae3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#how well a explanation matches the models predictions\n",
        "\n",
        "def fidelity_lime(pipeline, X_train, X_test, y_test, sample_size=10):\n",
        "    #Fidelity for LIME using R² of local surrogate\n",
        "\n",
        "    #keep original feature names\n",
        "    X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
        "    X_test_df  = pd.DataFrame(X_test, columns=X.columns)\n",
        "\n",
        "    explainer = LimeTabularExplainer(\n",
        "        training_data=X_train_df.values,\n",
        "        feature_names=X_train_df.columns.tolist(),\n",
        "        class_names=[\"No Disease\", \"Disease\"],\n",
        "        mode=\"classification\"\n",
        "    )\n",
        "\n",
        "    local_scores = []\n",
        "    #explain a few test samples\n",
        "    for i in range(min(sample_size, len(X_test_df))):\n",
        "        exp = explainer.explain_instance(\n",
        "            data_row=X_test_df.iloc[i].values,\n",
        "            predict_fn=lambda x: pipeline.predict_proba(pd.DataFrame(x, columns=X.columns))\n",
        "        )\n",
        "        local_scores.append(exp.score)  #R2 score for the local surrogate\n",
        "\n",
        "    return np.mean(local_scores)\n",
        "\n",
        "\n",
        "\n",
        "def fidelity_shap(pipeline, X_train, X_test, sample_size=50):\n",
        "    #correlation between true probs and SHAP reconstruction\n",
        "    preproc = pipeline.named_steps['preprocessor']\n",
        "    model   = pipeline.named_steps['classifier']\n",
        "\n",
        "    #preprocess data\n",
        "    X_train_proc = preproc.fit_transform(X_train)\n",
        "    X_test_proc  = preproc.transform(X_test)\n",
        "\n",
        "    #background and sample\n",
        "    background = shap.sample(X_train_proc, 50, random_state=42)\n",
        "    X_sample   = X_test_proc[:sample_size]\n",
        "\n",
        "    #only predict prob for class 1 (Heart disease)\n",
        "    f = lambda x: model.predict_proba(x)[:, 1]\n",
        "\n",
        "    explainer = shap.KernelExplainer(f, background)\n",
        "    shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "    expected_value = explainer.expected_value\n",
        "    reconstructed = expected_value + shap_values.sum(axis=1)\n",
        "\n",
        "    preds = f(X_sample)\n",
        "\n",
        "    #correlation between SHAP reconstruction and model probs\n",
        "    return float(np.corrcoef(preds, reconstructed)[0, 1])\n",
        "\n",
        "\n",
        "\n",
        "def fidelity_counterfactual(pipeline, X_train, X_test, y_train):\n",
        "    #how often a counterfactual can be generated.\n",
        "\n",
        "    df_train = X_train.copy()\n",
        "    df_train['target'] = y_train.values\n",
        "\n",
        "    data = dice_ml.Data(\n",
        "        dataframe=df_train,\n",
        "        continuous_features=X_train.columns.tolist(),\n",
        "        outcome_name=\"target\"\n",
        "    )\n",
        "    model = dice_ml.Model(model=pipeline, backend=\"sklearn\")\n",
        "    exp = Dice(data, model)\n",
        "\n",
        "    success = 0\n",
        "    total = min(20, len(X_test))  #keep runtime reasonable\n",
        "    for i in range(total):\n",
        "        e1 = exp.generate_counterfactuals(X_test.iloc[[i]], total_CFs=1, desired_class=\"opposite\")\n",
        "        if e1.cf_examples_list[0].final_cfs_df is not None:\n",
        "            success += 1\n",
        "    return success / total\n",
        "\n",
        "\n",
        "\n",
        "def fidelity_surrogate_tree(pipeline, X_test):\n",
        "    # how accurate the tree mimics\n",
        "\n",
        "    preds = pipeline.predict(X_test)\n",
        "    surrogate = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "    surrogate.fit(X_test, preds)\n",
        "    return surrogate.score(X_test, preds)\n",
        "\n",
        "def fidelity_pfi(pipeline, X_test, y_test):\n",
        "    #mean permutation importance\n",
        "\n",
        "    result = permutation_importance(pipeline, X_test, y_test, n_repeats=5, random_state=42)\n",
        "    return np.mean(result.importances_mean)\n",
        "\n",
        "\n",
        "def fidelity_pdp(pipeline, X_test):\n",
        "    #correlation of predictions with PDP averages\n",
        "\n",
        "    preds = pipeline.predict_proba(X_test)[:, 1]\n",
        "    pdp_values = []\n",
        "    for col in X_test.columns:\n",
        "        display = PartialDependenceDisplay.from_estimator(pipeline, X_test, [col])\n",
        "        avg_effect = np.mean(display.deciles[0])\n",
        "        pdp_values.append(avg_effect)\n",
        "        plt.close('all')  #avoid too many figures\n",
        "\n",
        "    if len(pdp_values) > 0:\n",
        "        return np.corrcoef(\n",
        "            preds,\n",
        "            np.tile(pdp_values, len(preds)//len(pdp_values)+1)[:len(preds)]\n",
        "        )[0, 1]\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "\n",
        "\n",
        "#Fidelity comparison across models\n",
        "\n",
        "fidelity_results = []\n",
        "\n",
        "#make sure data are DataFrames\n",
        "X_train_raw = pd.DataFrame(X_train_raw, columns=X.columns)\n",
        "X_test_raw  = pd.DataFrame(X_test_raw, columns=X.columns)\n",
        "\n",
        "for name, metrics in results.items():\n",
        "    pipeline = metrics[\"pipeline\"]\n",
        "    row = {\"Model\": name}\n",
        "\n",
        "    try:\n",
        "        row[\"LIME\"] = fidelity_lime(pipeline, X_train_raw, X_test_raw, y_test)\n",
        "    except Exception as e:\n",
        "        print(f\"LIME failed for {name}: {e}\")\n",
        "        row[\"LIME\"] = np.nan\n",
        "\n",
        "    try:\n",
        "        row[\"SHAP\"] = fidelity_shap(pipeline, X_train_raw, X_test_raw)\n",
        "    except Exception as e:\n",
        "        print(f\"SHAP failed for {name}: {e}\")\n",
        "        row[\"SHAP\"] = np.nan\n",
        "\n",
        "    try:\n",
        "        row[\"Counterfactual\"] = fidelity_counterfactual(pipeline, X_train_raw, X_test_raw, y_train)\n",
        "    except Exception as e:\n",
        "        print(f\"Counterfactuals failed for {name}: {e}\")\n",
        "        row[\"Counterfactual\"] = np.nan\n",
        "\n",
        "    try:\n",
        "        row[\"Surrogate Tree\"] = fidelity_surrogate_tree(pipeline, X_test_raw)\n",
        "    except Exception as e:\n",
        "        print(f\"Surrogate tree failed for {name}: {e}\")\n",
        "        row[\"Surrogate Tree\"] = np.nan\n",
        "\n",
        "    try:\n",
        "        row[\"PFI\"] = fidelity_pfi(pipeline, X_test_raw, y_test)\n",
        "    except Exception as e:\n",
        "        print(f\"PFI failed for {name}: {e}\")\n",
        "        row[\"PFI\"] = np.nan\n",
        "\n",
        "    try:\n",
        "        row[\"PDP\"] = fidelity_pdp(pipeline, X_test_raw)\n",
        "    except Exception as e:\n",
        "        print(f\"PDP failed for {name}: {e}\")\n",
        "        row[\"PDP\"] = np.nan\n",
        "\n",
        "    fidelity_results.append(row)\n",
        "\n",
        "#DataFrame for easy comparison\n",
        "fidelity_df = pd.DataFrame(fidelity_results)\n",
        "fidelity_df = fidelity_df.round(3)\n",
        "\n",
        "print(\"\\nFidelity Comparison Table:\")\n",
        "print(fidelity_df.to_markdown(index=False))\n"
      ],
      "metadata": {
        "id": "cxW0l49pOZzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wide table to long format seaborn barplot\n",
        "fidelity_long = fidelity_df.melt(id_vars=\"Model\", var_name=\"Method\", value_name=\"Fidelity\")\n",
        "\n",
        "# Barplot compares fidelity scores of each XAI method across models\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(\n",
        "    data=fidelity_long,\n",
        "    x=\"Method\",\n",
        "    y=\"Fidelity\",\n",
        "    hue=\"Model\",\n",
        "    palette=\"Set2\"\n",
        ")\n",
        "\n",
        "plt.title(\"Explainability Fidelity (per XAI Method)\")\n",
        "plt.ylabel(\"Fidelity Score\")\n",
        "plt.xlabel(\"XAI Method\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.legend(title=\"Model\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lydtjZzoFOi9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmKnWSBgh1mXkNtMh4ppxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}